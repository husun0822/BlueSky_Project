{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import sys\n",
    "from functools import partial\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib as mpl\n",
    "import collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edge_Filter(image,window_size=5,threshold=99):\n",
    "    '''This function aims at finding the PIL using a transformed image.\n",
    "    Basically, for each point in the image, we look at its neighborhood, with the point being the center a window of size\n",
    "    (window_size*window_size), and take the corresponding maximum and minimum out of it, and then take the difference, select the\n",
    "    points with the largest contrast, and whose window spans both positive and negative polars'''\n",
    "    image = np.nan_to_num(image)\n",
    "    \n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    \n",
    "    pos_weight = []\n",
    "    neg_weight = []\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            # Firstly, make the polarity of each pixel right\n",
    "\n",
    "            pixel = image[i,j]\n",
    "\n",
    "            if pixel>(1e-6):\n",
    "                pos_weight.append(np.abs(pixel))\n",
    "            elif pixel<-(1e-6):\n",
    "                neg_weight.append(np.abs(pixel))\n",
    "\n",
    "    pos_weight, neg_weight = np.array(pos_weight), np.array(neg_weight)\n",
    "    pos_threshold = np.percentile(pos_weight, q=threshold)\n",
    "    neg_threshold = np.percentile(neg_weight, q=threshold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    pad_size = int((window_size-1)/2)\n",
    "    image_padded = np.pad(image,((pad_size,pad_size),(pad_size,pad_size)),'constant')\n",
    "    \n",
    "    image_max = np.zeros((height,width))\n",
    "    image_min = np.zeros((height,width))\n",
    "    mask_image = np.zeros((height,width))\n",
    "    \n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            x = i+pad_size\n",
    "            y = j+pad_size\n",
    "            \n",
    "            window = image_padded[(x-pad_size):(x+pad_size+1),(y-pad_size):(y+pad_size+1)] # a sub-image\n",
    "            maximum = np.amax(window)\n",
    "            minimum = np.amin(window)\n",
    "            \n",
    "            image_max[i,j] = maximum\n",
    "            image_min[i,j] = minimum\n",
    "            if maximum>pos_threshold and minimum<-(neg_threshold):\n",
    "                mask_image[i,j] = image[i,j]\n",
    "                \n",
    "    return mask_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edge_Detection(image,threshold=99.5,image_threshold=97,radius=15,show=True,select=3,imagename='Nil'):\n",
    "    '''This function uses the skimage edge detection filters to find the PIL'''\n",
    "    image = Edge_Filter(image,threshold=image_threshold)\n",
    "    edge = scharr(image)\n",
    "    pixel_coor = []\n",
    "    pixel_weight = []\n",
    "    threshold = np.percentile(edge,threshold)\n",
    "    \n",
    "    for i in range(edge.shape[0]):\n",
    "        for j in range(edge.shape[1]):\n",
    "            if edge[i,j]<threshold:\n",
    "                edge[i,j]=0\n",
    "            else:\n",
    "                pixel_coor.append(np.array([i,j]))\n",
    "                pixel_weight.append(edge[i,j]) # the edge detection magnitude\n",
    "    \n",
    "    pixel_coor, pixel_weight = np.array(pixel_coor), np.array(pixel_weight)\n",
    "    # now we have the key pixels of interest stored in pixel_coor and pixel_weight\n",
    "    # now we do the clustering\n",
    "    clust = DBSCAN(eps=radius,min_samples=5)\n",
    "    thecluster = clust.fit_predict(X=pixel_coor)\n",
    "    \n",
    "    # now we are going to select the top few clusters with the largest sum of xy-gradient\n",
    "    N = len(set(thecluster))\n",
    "    cluster_coor = defaultdict(list)\n",
    "    cluster_gradient = defaultdict(list)\n",
    "    whole_data = list(zip(pixel_coor,pixel_weight,thecluster))\n",
    "    new_data = []\n",
    "    \n",
    "    if (-1) in thecluster:\n",
    "        N = N-1\n",
    "        for item in whole_data:\n",
    "            if item[2]!=-1:\n",
    "                new_data.append(item)\n",
    "    \n",
    "    for c in range(N):\n",
    "        cluster_coor[c] = [item[0] for item in new_data if item[2]==c]\n",
    "        cluster_gradient[c] = [item[1] for item in new_data if item[2]==c]\n",
    "        \n",
    "    cluster_sum = [sum(cluster_gradient[c]) for c in cluster_gradient]\n",
    "    if len(cluster_sum)>select:\n",
    "        top = np.argsort(cluster_sum)[-(select):] \n",
    "    else:\n",
    "        top = list(range(len(cluster_sum)))\n",
    "        \n",
    "    PIL_pixel = []\n",
    "    \n",
    "    for c in top:\n",
    "        coor = cluster_coor[c]\n",
    "        for point in coor:\n",
    "            PIL_pixel.append(point)\n",
    "    \n",
    "    PIL_pixel = np.array(PIL_pixel)\n",
    "                \n",
    "    if show==True:\n",
    "        N = len(set(thecluster))\n",
    "        cmap = plt.cm.jet\n",
    "        cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "        cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "        bounds = np.linspace(-1,N,N+2)\n",
    "        norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "        \n",
    "        fig = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        seaborn.heatmap(image, center=0, cbar=False,xticklabels=False, yticklabels=False)\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(pixel_coor[:, 1], pixel_coor[:, 0], c=thecluster,cmap=cmap, marker='o', s=0.5)\n",
    "        plt.xlim(0, image.shape[1])\n",
    "        plt.ylim(0, image.shape[0])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tick_params(labelbottom='off')\n",
    "        plt.tick_params(labelleft='off')\n",
    "\n",
    "        plt.show()\n",
    "    elif show=='select':\n",
    "        fig = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        seaborn.heatmap(image, center=0, cbar=False,xticklabels=False, yticklabels=False)\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(PIL_pixel[:, 1], PIL_pixel[:, 0], color='red',marker='o', s=0.05)\n",
    "        plt.xlim(0, image.shape[1])\n",
    "        plt.ylim(0, image.shape[0])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tick_params(labelbottom='off')\n",
    "        plt.tick_params(labelleft='off')\n",
    "        plt.savefig(imagename+'_s_f'+str(select)+'.pdf')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return PIL_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIL:\n",
    "    '''This class creates a PIL detector which can be called for fitting PIL on any Bz image or an entire hdf5 file.\n",
    "        \n",
    "       Summary on the class \"PIL\":\n",
    "       \n",
    "       For each image of the vertical component of the magnetic field, namely the image of \"Bz\", we want to find the \n",
    "       contour of Bz==0 that separates the strong positive magnetic polars and the associated negative polars, which \n",
    "       is called the Polarity Inversion Line(PIL). Physicists are interested in the local magnetic field features \n",
    "       around the PIL.\n",
    "       \n",
    "       In a pixelized image, the pixels that consist of the PIL should be those pixels that have a large Bz gradient in \n",
    "       its neighborhood. And finding these points is analogous to the edge detection task in the image processing field.\n",
    "       So by applying an edge detection filter upon each Bz image, we could find the candidate pixels of the PIL. And by \n",
    "       further applying a clustering algorithm on the candidate pixels, we are able to locate several PIL segments in the\n",
    "       image. Finally, one could retain, as many as one wanted, the PILs with large average gradients for future purposes.\n",
    "       \n",
    "       The class PIL is a parameterized PIL detector that combines the data preparation, edge detection, clustering and \n",
    "       parallelized training, and visualization procedures. It can be applied to a piece of image in numpy ndarray form, \n",
    "       and even an entire hdf5 file with rather fast implementation.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,edge_retain=0.005,polar_threshold=0.97,radius=15):\n",
    "        '''Initialize the PIL detector\n",
    "        \n",
    "           Params:\n",
    "           edge_retain: The fraction of candidate PIL pixels of the input image.\n",
    "                        What fraction of the pixels of the whole input image can be considered as a candidate for PIL. \n",
    "                        The larger the amount is, the more pixels there will be for the PIL. The default amount is 0.005\n",
    "                        which corresponds to 0.5% of all pixels in the input image. These pixels are the pixels with the \n",
    "                        largest local gradient. By specifying the edge_retain to be too large, we may include many irrelevant\n",
    "                        pixels when drawing the PIL. By setting the parameter to be too small, we may lose some pixels on\n",
    "                        the true PIL. The best way to tune the parameter is to use the .visualize() method to check visually. \n",
    "                        Generally speaking, each image won't have more than 1% of its pixels as PIL.\n",
    "                        \n",
    "           polar_threshold: The strong polar threshold.\n",
    "                            The quantile of the magnitude of the vertical component above which a pixel is considered as \n",
    "                            a strong polar. Basically, each image is decomposed into a positive image and a complementing\n",
    "                            negative image. In a positive image, all negative image pixels are coerced to 0, and vice versa.\n",
    "                            In the positive image, for instance, all pixels' values are ranked from the smallest to the \n",
    "                            largest, and all the pixels that are ranking at the quantile no greater than polar_threshold are\n",
    "                            further coerced to 0. The same procedure applies to the negative image. And the positive and \n",
    "                            negative image are put back together as a sparser image, upon which the edge detector will be\n",
    "                            applied. Setting the parameter too small can lead to many weaker polars being considered when\n",
    "                            drawing the PIL.\n",
    "                            \n",
    "           radius: The maximum pixel distance between two pixels that make the pixels being considered as on the same PIL. \n",
    "                   The larger the quantity, the less PIL segments will be drawn in the image, but maybe two originally \n",
    "                   separated PILs will be considered mistakenly as a single PIL.\n",
    "                        \n",
    "        '''\n",
    "        \n",
    "        self.edge_retain = edge_retain\n",
    "        self.polar_threshold = polar_threshold\n",
    "        self.radius = radius\n",
    "    \n",
    "    def Polar_Filter(self,image,window_size=5):\n",
    "        '''Data preparation step:\n",
    "        \n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
