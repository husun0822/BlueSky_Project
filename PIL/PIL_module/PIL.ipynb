{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import sys\n",
    "from functools import partial\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib as mpl\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from skimage.filters import scharr\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIL():\n",
    "    '''This class creates a PIL detector which can be called for fitting PIL on any Bz image or an entire hdf5 file.\n",
    "        \n",
    "       Summary on the class \"PIL\":\n",
    "       \n",
    "       For each image of the vertical component of the magnetic field, namely the image of \"Bz\", we want to find the \n",
    "       contour of Bz==0 that separates the strong positive magnetic polars and the associated negative polars, which \n",
    "       is called the Polarity Inversion Line(PIL). Physicists are interested in the local magnetic field features \n",
    "       around the PIL.\n",
    "       \n",
    "       In a pixelized image, the pixels that consist of the PIL should be those pixels that have a large Bz gradient in \n",
    "       its neighborhood. And finding these points is analogous to the edge detection task in the image processing field.\n",
    "       So by applying an edge detection filter upon each Bz image, we could find the candidate pixels of the PIL. And by \n",
    "       further applying a clustering algorithm on the candidate pixels, we are able to locate several PIL segments in the\n",
    "       image. Finally, one could retain, as many as one wanted, the PILs with large average gradients for future purposes.\n",
    "       \n",
    "       The class PIL is a parameterized PIL detector that combines the data preparation, edge detection, clustering and \n",
    "       parallelized training, and visualization procedures. It can be applied to a piece of image in numpy ndarray form, \n",
    "       and even an entire hdf5 file with rather fast implementation.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,edge_retain=0.005,polar_threshold=0.50,radius=12,min_samples=5):\n",
    "        '''Initialize the PIL detector\n",
    "        \n",
    "           Params:\n",
    "           edge_retain: The fraction of candidate PIL pixels of the input image. Range from 0 to 1. Float number.\n",
    "                        What fraction of the pixels of the whole input image can be considered as a candidate for PIL. \n",
    "                        The larger the amount is, the more pixels there will be for the PIL. The default amount is 0.005\n",
    "                        which corresponds to 0.5% of all pixels in the input image. These pixels are the pixels with the \n",
    "                        largest local gradient. By specifying the edge_retain to be too large, we may include many irrelevant\n",
    "                        pixels when drawing the PIL. By setting the parameter to be too small, we may lose some pixels on\n",
    "                        the true PIL. The best way to tune the parameter is to use the .visualize() method to check visually. \n",
    "                        Generally speaking, each image won't have more than 1% of its pixels as PIL.\n",
    "                        \n",
    "           polar_threshold: The strong polar threshold. Range from 0 to 1. Float number.\n",
    "                            The quantile of the magnitude of the vertical component above which a pixel is considered as \n",
    "                            a strong polar. Basically, each image is decomposed into a positive image and a complementing\n",
    "                            negative image. In a positive image, all negative image pixels are coerced to 0, and vice versa.\n",
    "                            In the positive image, for instance, all pixels' values are ranked from the smallest to the \n",
    "                            largest, and all the pixels that are ranking at the quantile no greater than polar_threshold are\n",
    "                            further coerced to 0. The same procedure applies to the negative image. And the positive and \n",
    "                            negative image are put back together as a sparser image, upon which the edge detector will be\n",
    "                            applied. Setting the parameter too small can lead to many weaker polars being considered when\n",
    "                            drawing the PIL.\n",
    "                            \n",
    "           radius: The maximum pixel distance between two pixels that make the pixels being considered as on the same PIL. Positive Integer. \n",
    "                   The larger the quantity, the less PIL segments will be drawn in the image, but maybe two originally \n",
    "                   separated PILs will be considered mistakenly as a single PIL.\n",
    "           \n",
    "           min_samples: The minimum number of pixels that a PIL segment should contain. Positive Integer.\n",
    "                        For a set of pixels to be considered as a PIL, one need at least min_samples in the set. By setting\n",
    "                        the parameter to be too large, we may mistakenly overlook those shorter PIL. On the contrast, we may\n",
    "                        include too many noisy PILs that are not ideal.\n",
    "        '''\n",
    "        \n",
    "        self.edge_retain = edge_retain\n",
    "        self.polar_threshold = polar_threshold*100\n",
    "        self.radius = radius\n",
    "        self.min_samples = min_samples\n",
    "        self.DBSCAN = DBSCAN(eps=self.radius,min_samples=self.min_samples) # set up the DBSCAN cluster operator for pixels clustering\n",
    "        self.PIL_segment = defaultdict(dict)\n",
    "        self.global_mode=False\n",
    "        \n",
    "    def Image_Decompose(self,image):\n",
    "        '''Data preparation method, a submethod for .data_preparation() method.\n",
    "           \n",
    "           Params:\n",
    "           image: Input image. Numpy array.\n",
    "                  Shape = [height,width]\n",
    "           \n",
    "           Output:\n",
    "           pos_weight: Numpy ndarray.\n",
    "                       Shape = [num_positive_pixels,]\n",
    "                       \n",
    "                       An array of all positive pixel values of the input image.\n",
    "                       \n",
    "           neg_weight: Numpy ndarray.\n",
    "                       Shape = [num_negative_pixels,]\n",
    "                       \n",
    "                       An array of all negative pixel values of the input image.\n",
    "        '''\n",
    "        image = np.nan_to_num(image) # fill the NaN value in an image as 0\n",
    "        \n",
    "        pos_weight = np.where(image>1e-6,image,0) # create a positive image component\n",
    "        neg_weight = np.where(image<-1e-6,image,0) # create a negative image component\n",
    "        \n",
    "        pos_weight, neg_weight = np.ndarray.flatten(pos_weight), np.ndarray.flatten(neg_weight) # collapse both image into 1-D\n",
    "        \n",
    "        pos_weight = pos_weight[np.nonzero(pos_weight)] # remove all 0s in the pos_weight\n",
    "        neg_weight = neg_weight[np.nonzero(neg_weight)] # remove all 0s in the neg_weight\n",
    "    \n",
    "        \n",
    "        return pos_weight, neg_weight\n",
    "    \n",
    "    def data_preparation(self,image,window_size=5):\n",
    "        '''Data preparation method, a submethod for the .fit() and .fitFile() method.\n",
    "        \n",
    "           Params:\n",
    "           image: Input image. Numpy array.\n",
    "                  Shape = [height,width]\n",
    "           \n",
    "           window_size: The range of a pixel's neighborhood. Odd number integer. No smaller than 3.\n",
    "                        For each pixel in the input image, we consider a window_size*window_size, 5*5 by default, subimage with\n",
    "                        the pixel of interest being at the center. \n",
    "                        \n",
    "           Output:\n",
    "           image_new: Output image ready for edge detection. Numpy array.\n",
    "                      Shape = [height, width], same as the input image.\n",
    "                      \n",
    "                      For each pixel in the original image, one consider the local maximum and local minimum of the pixel within\n",
    "                      its neighborhood. If both the local maximum and minimum passed the quantile threshold sepecified by \n",
    "                      self.polar_threshold in the corresponding positive and negative image, the pixel's value is retained,\n",
    "                      otherwise the pixel is put to zero.\n",
    "                      \n",
    "                      As a result, the output image only contains those pixels with both a strong positive and a strong negative\n",
    "                      polar within its neighborhood. This helps exclude those pixels with a strong positive/negative polar but \n",
    "                      no associative polar of the opposite polarity. So these pixels in the output image is a superset of PIL pixels.\n",
    "        '''\n",
    "        \n",
    "        image = np.nan_to_num(image) # fill all NaN in the image as 0\n",
    "        self.window_size = window_size # store the window_size attribute\n",
    "        \n",
    "        pos_weight, neg_weight = self.Image_Decompose(image)\n",
    "    \n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "            \n",
    "        pos_threshold = np.percentile(pos_weight, q=self.polar_threshold) # find the top quantile value of all positive pixels\n",
    "        neg_threshold = np.percentile(np.abs(neg_weight), q=self.polar_threshold) # find the top quantile value of all negative pixels\n",
    "    \n",
    "        pad_size = int((window_size-1)/2)\n",
    "        image_padded = np.pad(image,((pad_size,pad_size),(pad_size,pad_size)),'constant') # pad the image to make sure the output image has the same shape as the input image\n",
    "    \n",
    "        image_max = np.zeros((height,width)) # an image with each pixel storing its local maximum\n",
    "        image_min = np.zeros((height,width)) # an image with each pixel storing its local minimum\n",
    "        image_new = np.zeros((height,width)) # output image\n",
    "    \n",
    "    \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                x = i+pad_size\n",
    "                y = j+pad_size\n",
    "            \n",
    "                window = image_padded[(x-pad_size):(x+pad_size+1),(y-pad_size):(y+pad_size+1)] # the neighborhood subimage for each pixel\n",
    "                maximum = np.amax(window) # find the local maximum\n",
    "                minimum = np.amin(window) # find the local minimum\n",
    "            \n",
    "                image_max[i,j] = maximum\n",
    "                image_min[i,j] = minimum\n",
    "                if maximum>pos_threshold and minimum<-(neg_threshold): # retains the pixel value only if it has both a strong positive polar and a strong negative polar in its neighborhood subimage\n",
    "                    image_new[i,j] = image[i,j]\n",
    "                \n",
    "        return image_new\n",
    "    \n",
    "    def fit(self,image,select=1,window_size=5):\n",
    "        ''' Fit the whole PIL pipeline on the input image. Including the edge detection, clustering and filtering steps. Given\n",
    "            an input image, the fit method find all PIL pixels, and return two arrays containing information of the selected \n",
    "            PILs with the largest average local magnetic field gradient. Each PIL's information includes its corresponding pixels\n",
    "            and average local gradients.\n",
    "            \n",
    "            Params:\n",
    "            image: Input image. Numpy array.\n",
    "                   Shape = [height,width]\n",
    "            \n",
    "                   Original image upon which one wants to locate several PILs.\n",
    "            \n",
    "            select: Number of PILs to record. Positive Integer. Default is 1.\n",
    "                    \n",
    "                    Out of all PIL segments detected, how many of them are going to be recorded. All PIL segments are ranked \n",
    "                    according to their pixel-average local magnetic gradient, and only the PILs with the largest average gradient\n",
    "                    are recorded.\n",
    "            \n",
    "            window_size: The range of a pixel's neighborhood. Odd number integer. No smaller than 3.\n",
    "                         See description in method .data_preparation()\n",
    "            \n",
    "            Output: \n",
    "            PIL_segment: Information of the pixels of the selected PIL segments. Dictionary.\n",
    "                       \n",
    "                       The output is a dictionary: PIL_segment[segment_label]['coor'] = array of the coordinates of all pixels of the segment \n",
    "                                                   PIL_segment[segment_label]['gradient'] = average gradient of the PIL segment\n",
    "                                                   \n",
    "                       PIL segment labels are ranked in a descending order based on the average gradient.\n",
    "        '''\n",
    "        \n",
    "        image = self.data_preparation(image,window_size=window_size) # only retain the pixels with both a strong positive and a strong negative polar in the neighborhood\n",
    "        edge = scharr(image) # edge detection \n",
    "        \n",
    "        threshold = np.percentile(edge,q=100*(1-self.edge_retain)) # calculates the top quantile for local gradients\n",
    "    \n",
    "        # take records of the coordinates of all pixels that have a very large local graidents.\n",
    "        edge = np.where(edge>threshold,edge,0)\n",
    "        pixel_coor = np.transpose(np.nonzero(edge)) # these are the PIL candidates' coordinates\n",
    "        pixel_weight = list(map(lambda x: edge[x[0],x[1]],pixel_coor)) # the corresponding local gradient values for the PIL candidates\n",
    "        \n",
    "        thecluster = self.DBSCAN.fit_predict(X=pixel_coor) # cluster the PIL candidates into possibly several PIL segments.\n",
    "    \n",
    "        # now we are going to select the top few clusters with the largest average gradient\n",
    "        N = len(set(thecluster)) # number of PIL segments\n",
    "        cluster_coor = defaultdict(list) # a dictionary: cluster_coor[PIL_segment_label] = list of pixels of the PIL segment\n",
    "        cluster_gradient = defaultdict(list) # a dictionary: cluster_gradient[PIL_segment_label] = list of pixels' gradient of the PIL segment\n",
    "        \n",
    "        whole_data = list(zip(pixel_coor,pixel_weight,thecluster))\n",
    "        new_data = []\n",
    "        \n",
    "        # since there might be some PIL candidate pixels that do not even form a PIL segment, we should exclude all of these noisy points\n",
    "        if (-1) in thecluster:\n",
    "            N = N-1 \n",
    "        for item in whole_data:\n",
    "            if item[2]!=-1:\n",
    "                new_data.append(item)\n",
    "                    \n",
    "        if N!=0: # if all candidate points are noises, then do nothing\n",
    "\n",
    "            # record the coordinates information and gradient information for each of the PIL segment, namely each cluster\n",
    "            for c in range(N):\n",
    "                cluster_coor[c] = [item[0] for item in new_data if item[2]==c]\n",
    "                cluster_gradient[c] = [item[1] for item in new_data if item[2]==c]\n",
    "        \n",
    "            # calculate the segment average gradient and rank all PILs, select the top few PIL segments for final output\n",
    "            cluster_ave_gradient = [np.average(np.array(cluster_gradient[c])) for c in cluster_gradient]\n",
    "        \n",
    "            if len(cluster_ave_gradient)>select:\n",
    "                top = np.argsort(cluster_ave_gradient)[-(select):] \n",
    "            else:\n",
    "                top = np.argsort(cluster_ave_gradient)\n",
    "        \n",
    "            # record the coordinate information for the selected PIL segments\n",
    "            PIL_segment = defaultdict(dict)\n",
    "            order = list(reversed(top))\n",
    "        \n",
    "            for c in range(len(top)):\n",
    "                k = order[c]\n",
    "                coor = cluster_coor[k] # the list of coordinate of one of the top PIL segment\n",
    "                PIL_segment[c]['coor'] = np.array(coor)\n",
    "                PIL_segment[c]['weight'] = cluster_ave_gradient[k]\n",
    "    \n",
    "            self.PIL_segment = PIL_segment # PIL results\n",
    "            self.N = N # total PIL segments found\n",
    "            if self.global_mode==True:\n",
    "                return PIL_segment\n",
    "            \n",
    "        elif self.global_mode==False:\n",
    "            print(\"No PIL in the image!\")              \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIL_fit(image,edge_retain=0.003,polar_threshold=0.50,radius=12,min_samples=5,select=1,window_size=5,image_index=-1):\n",
    "    ''' An explicit function, instead of a class method, for fitting PIL over an image. Basically a class method wrapper.\n",
    "        \n",
    "        Params:\n",
    "        image, edge_retain, polar_threshold, radius, min_samples, select, window_size: see the PIL class documentation.\n",
    "        \n",
    "        image_index: the index of the image processed by this function. Useful if the multiprocessing of several frames is \n",
    "                     done asynchronously.\n",
    "        \n",
    "    '''\n",
    "    PIL_detector = PIL(edge_retain=edge_retain,polar_threshold=polar_threshold,radius=radius,min_samples=min_samples)\n",
    "    PIL_detector.global_mode = True\n",
    "    result = PIL_detector.fit(image,select=select,window_size=window_size)\n",
    "    \n",
    "    return result, image_index\n",
    "\n",
    "def PIL_fit_parallel(f,core=8,global_threshold=0.3,edge_retain=0.003,polar_threshold=0.50,\n",
    "                     radius=12,min_samples=5,select=1,window_size=5,filename='Nil'):\n",
    "    ''' Fit the PIL pipeline over all images in a numpy array file f/ hdf5 file f. For current python environment,\n",
    "            it is unsatisfactory that the class method .fit() cannot be made parallelized as a separate class method\n",
    "            since the multiprocessing module is not compatible with the pickle module. So we need to make the parallelization\n",
    "            explicitly in a process-oriented way.\n",
    "        \n",
    "            Params:\n",
    "            f: Input file. A file object.     \n",
    "               The input file for the whole HARP region, could be a numpy .npy file, or a .hdf5 file.\n",
    "               For npy file, its shape should be [num_frames,height,width]\n",
    "               For hdf5 file, its directory structure should be 'video0'->'frameXXX'->'channels'-> the Bz Image\n",
    "            \n",
    "            core: The number of processing cores for doing the parallalization.\n",
    "            \n",
    "            global_threshold: The percentile threshold used for selecting PILs throughout the whole video. Range from 0 to 1.\n",
    "                              When each image of the file has its PILs founded, all PILs throughout the video are compared\n",
    "                              based on their corresponding average gradient. And the quantile of the average gradient at\n",
    "                              the global_threshold is used to delete those weak PILs that have an average gradient that is\n",
    "                              below the quantile. The smaller it is, the more PILs will be retained for each image.\n",
    "            \n",
    "            edge_retain, polar_threshold, radius, min_samples, select, window_size: see the PIL class documentation.\n",
    "            \n",
    "            filename: The filename for saving the output file. No extensions needed.\n",
    "            \n",
    "            Output:\n",
    "            PIL_file: In case of a numpy array input, output a pickled dictionary. In cased of hdf5 file, output a corresponding\n",
    "                      hdf5. Saved in the same folder.                      \n",
    "        '''\n",
    "    \n",
    "    pool = mp.Pool(processes=core)\n",
    "    process_input = []\n",
    "    \n",
    "    if type(f)==np.ndarray:\n",
    "        for i in range(f.shape[0]):\n",
    "            the_input = [f[i],edge_retain,polar_threshold,radius,min_samples,select,window_size,i]\n",
    "            process_input.append(the_input)\n",
    "        \n",
    "        results = [pool.apply_async(PIL_fit,t) for t in process_input]\n",
    "        output = [p.get() for p in results]\n",
    "        final_result = defaultdict(dict)\n",
    "        all_gradient = [] # a list of PILs' gradients\n",
    "        \n",
    "        for item in output:\n",
    "            PIL_segment = item[0] # retain the result from an image\n",
    "            if len(PIL_segment.keys())>0: # check if any PILs are found in the image\n",
    "                for segment in PIL_segment:\n",
    "                    all_gradient.append(PIL_segment[segment]['weight']) # store the weight value in all_gradient so as to do global thresholding on all images.\n",
    "        \n",
    "        threshold = np.percentile(np.array(all_gradient),q=100*global_threshold) # this threshold is to cut off those weak PILs\n",
    "        \n",
    "        for item in output:\n",
    "            thekey = item[1]\n",
    "            PIL_segment = item[0]\n",
    "            if len(PIL_segment.keys())==0: # if no PIL for the image\n",
    "                final_result[thekey] = PIL_segment # store the result in a dictionary\n",
    "            else:\n",
    "                L = list(PIL_segment)\n",
    "                for line in L: # if there is any PIL for the image\n",
    "                    if PIL_segment[line]['weight']>threshold:\n",
    "                        continue\n",
    "                    else:\n",
    "                        del PIL_segment[line] # if the gradient for the PIL is too small, throw the PIL away\n",
    "                \n",
    "                final_result[thekey] = PIL_segment # store the result in a dictionary\n",
    "            \n",
    "        with open(filename + '.pkl', 'wb') as f:\n",
    "            pickle.dump(final_result, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Output Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = PIL_fit_parallel(test_data,core=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = PIL_fit(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(dict, {0: {'coor': array([[152, 209],\n",
       "                      [152, 210],\n",
       "                      [152, 211],\n",
       "                      ...,\n",
       "                      [238, 292],\n",
       "                      [239, 290],\n",
       "                      [239, 291]], dtype=int64),\n",
       "               'weight': 347.9767842588881}}),\n",
       " -1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = PIL(edge_retain=0.003,polar_threshold=0.50,radius=12,min_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('HARP377.npy')\n",
    "test_data = data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data[800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tool.fitFile(test_data,select=2,window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.fit(image,select=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {0: {'coor': array([[222, 441],\n",
       "                     [222, 442],\n",
       "                     [223, 441],\n",
       "                     ...,\n",
       "                     [259, 457],\n",
       "                     [259, 458],\n",
       "                     [259, 459]], dtype=int64), 'weight': 92.13377611488512}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.PIL_segment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
