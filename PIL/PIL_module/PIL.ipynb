{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import multiprocessing as mp\n",
    "import glob\n",
    "import sys\n",
    "from functools import partial\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib as mpl\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "from skimage.filters import scharr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edge_Filter(image,window_size=5,threshold=99):\n",
    "    '''This function aims at finding the PIL using a transformed image.\n",
    "    Basically, for each point in the image, we look at its neighborhood, with the point being the center a window of size\n",
    "    (window_size*window_size), and take the corresponding maximum and minimum out of it, and then take the difference, select the\n",
    "    points with the largest contrast, and whose window spans both positive and negative polars'''\n",
    "    image = np.nan_to_num(image)\n",
    "    \n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    \n",
    "    pos_weight = []\n",
    "    neg_weight = []\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            # Firstly, make the polarity of each pixel right\n",
    "\n",
    "            pixel = image[i,j]\n",
    "\n",
    "            if pixel>(1e-6):\n",
    "                pos_weight.append(np.abs(pixel))\n",
    "            elif pixel<-(1e-6):\n",
    "                neg_weight.append(np.abs(pixel))\n",
    "\n",
    "    pos_weight, neg_weight = np.array(pos_weight), np.array(neg_weight)\n",
    "    pos_threshold = np.percentile(pos_weight, q=threshold)\n",
    "    neg_threshold = np.percentile(neg_weight, q=threshold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    pad_size = int((window_size-1)/2)\n",
    "    image_padded = np.pad(image,((pad_size,pad_size),(pad_size,pad_size)),'constant')\n",
    "    \n",
    "    image_max = np.zeros((height,width))\n",
    "    image_min = np.zeros((height,width))\n",
    "    mask_image = np.zeros((height,width))\n",
    "    \n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            x = i+pad_size\n",
    "            y = j+pad_size\n",
    "            \n",
    "            window = image_padded[(x-pad_size):(x+pad_size+1),(y-pad_size):(y+pad_size+1)] # a sub-image\n",
    "            maximum = np.amax(window)\n",
    "            minimum = np.amin(window)\n",
    "            \n",
    "            image_max[i,j] = maximum\n",
    "            image_min[i,j] = minimum\n",
    "            if maximum>pos_threshold and minimum<-(neg_threshold):\n",
    "                mask_image[i,j] = image[i,j]\n",
    "                \n",
    "    return mask_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edge_Detection(image,threshold=99.5,image_threshold=97,radius=15,show=True,select=3,imagename='Nil'):\n",
    "    '''This function uses the skimage edge detection filters to find the PIL'''\n",
    "    image = Edge_Filter(image,threshold=image_threshold)\n",
    "    edge = scharr(image)\n",
    "    pixel_coor = []\n",
    "    pixel_weight = []\n",
    "    threshold = np.percentile(edge,threshold)\n",
    "    \n",
    "    for i in range(edge.shape[0]):\n",
    "        for j in range(edge.shape[1]):\n",
    "            if edge[i,j]<threshold:\n",
    "                edge[i,j]=0\n",
    "            else:\n",
    "                pixel_coor.append(np.array([i,j]))\n",
    "                pixel_weight.append(edge[i,j]) # the edge detection magnitude\n",
    "    \n",
    "    pixel_coor, pixel_weight = np.array(pixel_coor), np.array(pixel_weight)\n",
    "    # now we have the key pixels of interest stored in pixel_coor and pixel_weight\n",
    "    # now we do the clustering\n",
    "    clust = DBSCAN(eps=radius,min_samples=5)\n",
    "    thecluster = clust.fit_predict(X=pixel_coor)\n",
    "    \n",
    "    # now we are going to select the top few clusters with the largest sum of xy-gradient\n",
    "    N = len(set(thecluster))\n",
    "    cluster_coor = defaultdict(list)\n",
    "    cluster_gradient = defaultdict(list)\n",
    "    whole_data = list(zip(pixel_coor,pixel_weight,thecluster))\n",
    "    new_data = []\n",
    "    \n",
    "    if (-1) in thecluster:\n",
    "        N = N-1\n",
    "        for item in whole_data:\n",
    "            if item[2]!=-1:\n",
    "                new_data.append(item)\n",
    "    \n",
    "    for c in range(N):\n",
    "        cluster_coor[c] = [item[0] for item in new_data if item[2]==c]\n",
    "        cluster_gradient[c] = [item[1] for item in new_data if item[2]==c]\n",
    "        \n",
    "    cluster_sum = [sum(cluster_gradient[c]) for c in cluster_gradient]\n",
    "    if len(cluster_sum)>select:\n",
    "        top = np.argsort(cluster_sum)[-(select):] \n",
    "    else:\n",
    "        top = list(range(len(cluster_sum)))\n",
    "        \n",
    "    PIL_pixel = []\n",
    "    \n",
    "    for c in top:\n",
    "        coor = cluster_coor[c]\n",
    "        for point in coor:\n",
    "            PIL_pixel.append(point)\n",
    "    \n",
    "    PIL_pixel = np.array(PIL_pixel)\n",
    "                \n",
    "    if show==True:\n",
    "        N = len(set(thecluster))\n",
    "        cmap = plt.cm.jet\n",
    "        cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "        cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "        bounds = np.linspace(-1,N,N+2)\n",
    "        norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "        \n",
    "        fig = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        seaborn.heatmap(image, center=0, cbar=False,xticklabels=False, yticklabels=False)\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(pixel_coor[:, 1], pixel_coor[:, 0], c=thecluster,cmap=cmap, marker='o', s=0.5)\n",
    "        plt.xlim(0, image.shape[1])\n",
    "        plt.ylim(0, image.shape[0])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tick_params(labelbottom='off')\n",
    "        plt.tick_params(labelleft='off')\n",
    "\n",
    "        plt.show()\n",
    "    elif show=='select':\n",
    "        fig = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        seaborn.heatmap(image, center=0, cbar=False,xticklabels=False, yticklabels=False)\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(PIL_pixel[:, 1], PIL_pixel[:, 0], color='red',marker='o', s=0.05)\n",
    "        plt.xlim(0, image.shape[1])\n",
    "        plt.ylim(0, image.shape[0])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tick_params(labelbottom='off')\n",
    "        plt.tick_params(labelleft='off')\n",
    "        plt.savefig(imagename+'_s_f'+str(select)+'.pdf')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return PIL_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIL:\n",
    "    '''This class creates a PIL detector which can be called for fitting PIL on any Bz image or an entire hdf5 file.\n",
    "        \n",
    "       Summary on the class \"PIL\":\n",
    "       \n",
    "       For each image of the vertical component of the magnetic field, namely the image of \"Bz\", we want to find the \n",
    "       contour of Bz==0 that separates the strong positive magnetic polars and the associated negative polars, which \n",
    "       is called the Polarity Inversion Line(PIL). Physicists are interested in the local magnetic field features \n",
    "       around the PIL.\n",
    "       \n",
    "       In a pixelized image, the pixels that consist of the PIL should be those pixels that have a large Bz gradient in \n",
    "       its neighborhood. And finding these points is analogous to the edge detection task in the image processing field.\n",
    "       So by applying an edge detection filter upon each Bz image, we could find the candidate pixels of the PIL. And by \n",
    "       further applying a clustering algorithm on the candidate pixels, we are able to locate several PIL segments in the\n",
    "       image. Finally, one could retain, as many as one wanted, the PILs with large average gradients for future purposes.\n",
    "       \n",
    "       The class PIL is a parameterized PIL detector that combines the data preparation, edge detection, clustering and \n",
    "       parallelized training, and visualization procedures. It can be applied to a piece of image in numpy ndarray form, \n",
    "       and even an entire hdf5 file with rather fast implementation.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,edge_retain=0.005,polar_threshold=0.97,radius=15,min_samples=5):\n",
    "        '''Initialize the PIL detector\n",
    "        \n",
    "           Params:\n",
    "           edge_retain: The fraction of candidate PIL pixels of the input image. Range from 0 to 1. Float number.\n",
    "                        What fraction of the pixels of the whole input image can be considered as a candidate for PIL. \n",
    "                        The larger the amount is, the more pixels there will be for the PIL. The default amount is 0.005\n",
    "                        which corresponds to 0.5% of all pixels in the input image. These pixels are the pixels with the \n",
    "                        largest local gradient. By specifying the edge_retain to be too large, we may include many irrelevant\n",
    "                        pixels when drawing the PIL. By setting the parameter to be too small, we may lose some pixels on\n",
    "                        the true PIL. The best way to tune the parameter is to use the .visualize() method to check visually. \n",
    "                        Generally speaking, each image won't have more than 1% of its pixels as PIL.\n",
    "                        \n",
    "           polar_threshold: The strong polar threshold. Range from 0 to 1. Float number.\n",
    "                            The quantile of the magnitude of the vertical component above which a pixel is considered as \n",
    "                            a strong polar. Basically, each image is decomposed into a positive image and a complementing\n",
    "                            negative image. In a positive image, all negative image pixels are coerced to 0, and vice versa.\n",
    "                            In the positive image, for instance, all pixels' values are ranked from the smallest to the \n",
    "                            largest, and all the pixels that are ranking at the quantile no greater than polar_threshold are\n",
    "                            further coerced to 0. The same procedure applies to the negative image. And the positive and \n",
    "                            negative image are put back together as a sparser image, upon which the edge detector will be\n",
    "                            applied. Setting the parameter too small can lead to many weaker polars being considered when\n",
    "                            drawing the PIL.\n",
    "                            \n",
    "           radius: The maximum pixel distance between two pixels that make the pixels being considered as on the same PIL. Positive Integer. \n",
    "                   The larger the quantity, the less PIL segments will be drawn in the image, but maybe two originally \n",
    "                   separated PILs will be considered mistakenly as a single PIL.\n",
    "           \n",
    "           min_samples: The minimum number of pixels that a PIL segment should contain. Positive Integer.\n",
    "                        For a set of pixels to be considered as a PIL, one need at least min_samples in the set. By setting\n",
    "                        the parameter to be too large, we may mistakenly overlook those shorter PIL. On the contrast, we may\n",
    "                        include too many noisy PILs that are not ideal.\n",
    "        '''\n",
    "        \n",
    "        self.edge_retain = edge_retain\n",
    "        self.polar_threshold = polar_threshold*100\n",
    "        self.radius = radius\n",
    "        self.min_samples = min_samples\n",
    "        self.DBSCAN = DBSCAN(eps=self.radius,min_samples=self.min_samples) # set up the DBSCAN cluster operator for pixels clustering\n",
    "        self.image = None\n",
    "        self.file = None\n",
    "        self.PIL_segment = dict()\n",
    "        \n",
    "    def Image_Decompose(self,image):\n",
    "        '''Data preparation method, a submethod for .data_preparation() method.\n",
    "           \n",
    "           Params:\n",
    "           image: Input image. Numpy array.\n",
    "                  Shape = [height,width]\n",
    "           \n",
    "           Output:\n",
    "           pos_weight: Numpy ndarray.\n",
    "                       Shape = [num_positive_pixels,]\n",
    "                       \n",
    "                       An array of all positive pixel values of the input image.\n",
    "                       \n",
    "           neg_weight: Numpy ndarray.\n",
    "                       Shape = [num_negative_pixels,]\n",
    "                       \n",
    "                       An array of all negative pixel values of the input image.\n",
    "        '''\n",
    "        image = np.nan_to_num(image) # fill the NaN value in an image as 0\n",
    "        \n",
    "        pos_weight = np.where(image>1e-6,image,0) # create a positive image component\n",
    "        neg_weight = np.where(image<-1e-6,image,0) # create a negative image component\n",
    "        \n",
    "        pos_weight, neg_weight = np.ndarray.flatten(pos_weight), np.ndarray.flatten(neg_weight) # collapse both image into 1-D\n",
    "        \n",
    "        pos_weight = pos_weight[np.nonzero(pos_weight)] # remove all 0s in the pos_weight\n",
    "        neg_weight = neg_weight[np.nonzero(neg_weight)] # remove all 0s in the neg_weight\n",
    "    \n",
    "        \n",
    "        return pos_weight, neg_weight\n",
    "    \n",
    "    def data_preparation(self,image,window_size=5):\n",
    "        '''Data preparation method, a submethod for the .fit() and .fitFile() method.\n",
    "        \n",
    "           Params:\n",
    "           image: Input image. Numpy array.\n",
    "                  Shape = [height,width]\n",
    "           \n",
    "           window_size: The range of a pixel's neighborhood. Odd number integer. No smaller than 3.\n",
    "                        For each pixel in the input image, we consider a window_size*window_size, 5*5 by default, subimage with\n",
    "                        the pixel of interest being at the center. \n",
    "                        \n",
    "           Output:\n",
    "           image_new: Output image ready for edge detection. Numpy array.\n",
    "                      Shape = [height, width], same as the input image.\n",
    "                      \n",
    "                      For each pixel in the original image, one consider the local maximum and local minimum of the pixel within\n",
    "                      its neighborhood. If both the local maximum and minimum passed the quantile threshold sepecified by \n",
    "                      self.polar_threshold in the corresponding positive and negative image, the pixel's value is retained,\n",
    "                      otherwise the pixel is put to zero.\n",
    "                      \n",
    "                      As a result, the output image only contains those pixels with both a strong positive and a strong negative\n",
    "                      polar within its neighborhood. This helps exclude those pixels with a strong positive/negative polar but \n",
    "                      no associative polar of the opposite polarity. So these pixels in the output image is a superset of PIL pixels.\n",
    "        '''\n",
    "        \n",
    "        image = np.nan_to_num(image) # fill all NaN in the image as 0\n",
    "        self.window_size = window_size # store the window_size attribute\n",
    "        \n",
    "        pos_weight, neg_weight = self.Image_Decompose(image)\n",
    "    \n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "            \n",
    "        pos_threshold = np.percentile(pos_weight, q=self.polar_threshold) # find the top quantile value of all positive pixels\n",
    "        neg_threshold = np.percentile(np.abs(neg_weight), q=self.polar_threshold) # find the top quantile value of all negative pixels\n",
    "    \n",
    "        pad_size = int((window_size-1)/2)\n",
    "        image_padded = np.pad(image,((pad_size,pad_size),(pad_size,pad_size)),'constant') # pad the image to make sure the output image has the same shape as the input image\n",
    "    \n",
    "        image_max = np.zeros((height,width)) # an image with each pixel storing its local maximum\n",
    "        image_min = np.zeros((height,width)) # an image with each pixel storing its local minimum\n",
    "        image_new = np.zeros((height,width)) # output image\n",
    "    \n",
    "    \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                x = i+pad_size\n",
    "                y = j+pad_size\n",
    "            \n",
    "                window = image_padded[(x-pad_size):(x+pad_size+1),(y-pad_size):(y+pad_size+1)] # the neighborhood subimage for each pixel\n",
    "                maximum = np.amax(window) # find the local maximum\n",
    "                minimum = np.amin(window) # find the local minimum\n",
    "            \n",
    "                image_max[i,j] = maximum\n",
    "                image_min[i,j] = minimum\n",
    "                if maximum>pos_threshold and minimum<-(neg_threshold): # retains the pixel value only if it has both a strong positive polar and a strong negative polar in its neighborhood subimage\n",
    "                    image_new[i,j] = image[i,j]\n",
    "                \n",
    "        return image_new\n",
    "    \n",
    "    def fit(self,image,select=1,window_size=5):\n",
    "        ''' Fit the whole PIL pipeline on the input image. Including the edge detection, clustering and filtering steps. Given\n",
    "            an input image, the fit method find all PIL pixels, and return two arrays containing information of the selected \n",
    "            PILs with the largest average local magnetic field gradient. Each PIL's information includes its corresponding pixels\n",
    "            and average local gradients.\n",
    "            \n",
    "            Params:\n",
    "            image: Input image. Numpy array.\n",
    "                   Shape = [height,width]\n",
    "            \n",
    "                   Original image upon which one wants to locate several PILs.\n",
    "            \n",
    "            select: Number of PILs to record. Positive Integer. Default is 1.\n",
    "                    \n",
    "                    Out of all PIL segments detected, how many of them are going to be recorded. All PIL segments are ranked \n",
    "                    according to their pixel-average local magnetic gradient, and only the PILs with the largest average gradient\n",
    "                    are recorded.\n",
    "            \n",
    "            window_size: The range of a pixel's neighborhood. Odd number integer. No smaller than 3.\n",
    "                         See description in method .data_preparation()\n",
    "            \n",
    "            Output: \n",
    "            PIL_segment: Information of the pixels of the selected PIL segments. Dictionary.\n",
    "                       \n",
    "                       The output is a dictionary: PIL_segment[segment_label]['coor'] = array of the coordinates of all pixels of the segment \n",
    "                                                   PIL_segment[segment_label]['gradient'] = average gradient of the PIL segment\n",
    "                                                   \n",
    "                       PIL segment labels are ranked in a descending order based on the average gradient.\n",
    "        '''\n",
    "        \n",
    "        image = self.data_preparation(image,window_size=window_size) # only retain the pixels with both a strong positive and a strong negative polar in the neighborhood\n",
    "        edge = scharr(image) # edge detection \n",
    "        \n",
    "        threshold = np.percentile(edge,q=100*(1-self.edge_retain)) # calculates the top quantile for local gradients\n",
    "    \n",
    "        # take records of the coordinates of all pixels that have a very large local graidents.\n",
    "        edge = np.where(edge>threshold,edge,0)\n",
    "        pixel_coor = np.transpose(np.nonzero(edge)) # these are the PIL candidates' coordinates\n",
    "        pixel_weight = list(map(lambda x: edge[x[0],x[1]],pixel_coor)) # the corresponding local gradient values for the PIL candidates\n",
    "        \n",
    "        thecluster = self.DBSCAN.fit_predict(X=pixel_coor) # cluster the PIL candidates into possibly several PIL segments.\n",
    "    \n",
    "        # now we are going to select the top few clusters with the largest average gradient\n",
    "        N = len(set(thecluster)) # number of PIL segments\n",
    "        cluster_coor = defaultdict(list) # a dictionary: cluster_coor[PIL_segment_label] = list of pixels of the PIL segment\n",
    "        cluster_gradient = defaultdict(list) # a dictionary: cluster_gradient[PIL_segment_label] = list of pixels' gradient of the PIL segment\n",
    "        \n",
    "        whole_data = list(zip(pixel_coor,pixel_weight,thecluster))\n",
    "        new_data = []\n",
    "        \n",
    "        # since there might be some PIL candidate pixels that do not even form a PIL segment, we should exclude all of these noisy points\n",
    "        if (-1) in thecluster:\n",
    "            N = N-1 \n",
    "            for item in whole_data:\n",
    "                if item[2]!=-1:\n",
    "                    new_data.append(item)\n",
    "        \n",
    "        # record the coordinates information and gradient information for each of the PIL segment, namely each cluster\n",
    "        for c in range(N):\n",
    "            cluster_coor[c] = [item[0] for item in new_data if item[2]==c]\n",
    "            cluster_gradient[c] = [item[1] for item in new_data if item[2]==c]\n",
    "        \n",
    "        # calculate the segment average gradient and rank all PILs, select the top few PIL segments for final output\n",
    "        cluster_ave_gradient = [np.average(cluster_gradient[c]) for c in cluster_gradient]\n",
    "        \n",
    "        if len(cluster_ave_gradient)>select:\n",
    "            top = np.argsort(cluster_ave_gradient)[-(select):] \n",
    "        else:\n",
    "            top = np.argsort(cluster_ave_gradient)\n",
    "        \n",
    "        # record the coordinate information for the selected PIL segments\n",
    "        PIL_segment = defaultdict(dict)\n",
    "        order = list(reversed(top))\n",
    "        \n",
    "        for c in range(len(top)):\n",
    "            k = order[c]\n",
    "            coor = cluster_coor[k] # the list of coordinate of one of the top PIL segment\n",
    "            PIL_segment[c]['coor'] = np.array(coor)\n",
    "            PIL_segment[c]['weight'] = cluster_ave_gradient[k]\n",
    "    \n",
    "        self.PIL_segment = PIL_segment\n",
    "    \n",
    "    def fitFile(self,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('HARP377.npy')\n",
    "image = data[800,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = PIL(edge_retain=0.003,polar_threshold=0.50,radius=12,min_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.fit(image,select=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347.9767842588881"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.PIL_segment[0]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.PIL_segment.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data[800,:,:]\n",
    "result = Edge_Detection(image,threshold=99.7,image_threshold=50,radius=12,show=False,select=2,imagename='image800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
